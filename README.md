# Awesome SMLs

This is the list of the SMLs I use on my Raspberry Pi5 (8GB RAM) with [Ollama](https://ollama.com/):

| Name                     | Size  | Remark                                                                                                | URL                                                        | Good on Pi5 | Usable on Pi5 |
| ------------------------ | ----- | ----------------------------------------------------------------------------------------------------- | ---------------------------------------------------------- | ----------- | ------------- |
| CodeGemma 2b             | 1.6GB | Fill-in-the-middle code completion                                                                    | https://ollama.com/library/codegemma:2b                    |             | x             |
| Gemma 2b                 | 1.7GB |                                                                                                       | https://ollama.com/library/gemma:2b                        |             | x             |
| Gemma2 2b                | 1.6GB |                                                                                                       | https://ollama.com/library/gemma2:2b                       |             |               |
| All-Minilm 22m           | 46MB  | Only Embeddings                                                                                       | https://ollama.com/library/all-minilm:22m                  | x           | x             |
| All-Minilm 33m           | 67MB  | Only Embeddings                                                                                       | https://ollama.com/library/all-minilm:33m                  |             |               |
| DeepSeek Coder 1.3b      | 776MB | Trained on both 87% code and 13% natural language                                                     | https://ollama.com/library/deepseek-coder                  | x           | x             |
| TinyLlama 1.1b           | 638MB |                                                                                                       | https://ollama.com/library/tinyllama                       | x           | x             |
| TinyDolphin 1.1b         | 637MB |                                                                                                       | https://ollama.com/library/tinydolphin                     | x           | x             |
| Phi3 Mini                | 2.4GB |                                                                                                       | https://ollama.com/library/phi3:mini                       |             | x             |
| Granite-code 3b          | 2.0GB |                                                                                                       | https://ollama.com/library/granite-code                    |             | x             |
| Qwen2 0.5b               | 352MB |                                                                                                       | https://ollama.com/library/qwen2:0.5b                      | x           | x             |
| Qwen 0.5b                | 395MB |                                                                                                       | https://ollama.com/library/qwen:0.5b                       | x           | x             |
| StarCoder 1b             | 726MB | Code generation model                                                                                 | https://ollama.com/library/starcoder:1b                    | x           | x             |
| StarCoder2 3b            | 1.7GB |                                                                                                       | https://ollama.com/library/starcoder2:3b                   |             | x             |
| Stable LM 2 1.6b         | 983MB | LLM trained on multilingual data in English, Spanish, German, Italian, French, Portuguese, and Dutch. | https://ollama.com/library/stablelm2                       | x           | x             |
| Stable Code 3b           | 1.6GB | Coding model                                                                                          | https://ollama.com/library/stable-code:3b                  |             | x             |
| Replete-Coder Qwen2 1.5b | 1.9GB | Coding capabilities + non-coding data, fully cleaned and uncensored                                   | https://ollama.com/rouge/replete-coder-qwen2-1.5b:Q8       | x           | x             |
| Dolphin-Phi 2.7b         | 1.6GB | uncensored                                                                                            | https://ollama.com/library/dolphin-phi:2.7b                |             |               |
| Dolphin gemma2 2b        | 1.6GB |                                                                                                       | https://ollama.com/CognitiveComputations/dolphin-gemma2:2b |             |               |
|                          |       |                                                                                                       |                                                            |             |               |


